% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/assessment_center.R
\name{assessment_center}
\alias{assessment_center}
\title{Assess multiple models on a single data set}
\usage{
assessment_center(
  model_spec_list,
  data_spec,
  perf_plot_spec,
  model_tree_mirror = c("models", "results"),
  comparison_plot = TRUE,
  quiet = FALSE
)
}
\arguments{
\item{model_spec_list}{list of ModelSpec objects. Assess these models.}

\item{data_spec}{DataSpec object. Assess on this data set.}

\item{perf_plot_spec}{PerfPlotSpec object. Specify the final comparison plot.
We derive the \code{PerfPlotSpec} for the single plots in a reasonable way from it.}

\item{model_tree_mirror}{character vector of lengtgh 2. This answers the question
where to store the generated assessment files.
\itemize{
\item For the train cohort, it is the model directory (where the fit lies as an rds
file).
\item For the test cohort, it is the same directory as for the train cohort, with one
exception: we mirror the file path according to \code{model_tree_mirror}, i.e., we
replace the first element of \code{model_tree_mirror} by the second element. Default
is \code{c("models", "results")}.
}}

\item{comparison_plot}{logical. Whether to generate the above mentioned comparison
plot. Default is \code{TRUE}.}

\item{quiet}{logical. Whether to suppress messages. Default is \code{FALSE}.}
}
\description{
Assess the performance of multiple models on a single data set.
For every
\itemize{
\item cohort (train and test),
\item model and
\item time cutoff this model specifies,
call \code{\link[=assess_model]{assess_model()}}. In addition, plot \code{x_metric} vs. \code{y_metric} attribute
of \code{PerfPlotSpec} for all models in a sinlge plot ("comparison plot").
}
}
